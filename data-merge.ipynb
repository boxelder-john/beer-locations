{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd, os, numpy as np, requests, json\n",
    "from time import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a new dataframe to contain the union of the combined spreadsheets, add year and full_address columns\n",
    "entities = pd.DataFrame()\n",
    "entities['year'] = np.nan\n",
    "entities['full_address'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# specify necessary fields with a data type of string\n",
    "data_types = {'ZIP':str, 'ID':str, 'COUNTRY':str}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2005.xlsx 2006.xlsx 2007.xlsx 2008.xls 2009.xlsx 2010.xlsx 2011.xlsx 2012.xlsx 2013.xlsx 2014.xlsx 2015.xlsx\n"
     ]
    }
   ],
   "source": [
    "# for each excel file in the data directory, load it and add its contents to the dataframe\n",
    "for filename in os.listdir('data/'):\n",
    "    if filename.endswith('.xls') or filename.endswith('.xlsx'):\n",
    "        print filename,\n",
    "        df_temp = pd.read_excel('data/' + filename, encoding='utf-8', converters=data_types)\n",
    "        df_temp['year'] = filename[0:4]\n",
    "        entities = pd.concat([entities, df_temp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# rename columns to all lower case\n",
    "entities_columns = ['address', 'city', 'country', 'id', 'last_update', 'name', \n",
    "                    'state', 'type', 'updated', 'x', 'y', 'zip', 'full_address', 'year']\n",
    "entities.columns = entities_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([u'MN', u'CA', u'CO', u'KS', u'MO', u'FL', u'IA', u'LA', u'NY',\n",
       "       u'WI', u'SC', u'OR', u'AK', u'IN', u'VT', u'ME', u'WA', u'WY',\n",
       "       u'IL', u'MA', u'NC', u'PA', u'MI', u'NM', u'GA', u'MD', u'VA',\n",
       "       u'AZ', u'TN', u'MT', u'OH', u'NV', u'NJ', u'OK', u'ID', u'TX',\n",
       "       u'WV', u'KY', u'UT', u'AR', u'HI', u'CT', u'DC', u'MS', u'RI',\n",
       "       u'NE', u'SD', u'DE', u'NH', u'ND', u'AL', u'QC', u'ON', u'BC',\n",
       "       u'AB', u'NB', u'SK', u'NL', u'PEI', u'NS', u'MB', u'YT', u'PE'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what state/province entities are represented in this data set?\n",
    "entities['state'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# only retain U.S. rows: drop the rows with a canadian province in the state column\n",
    "canadian_provinces = ['YT', 'PE', 'PEI', 'MB', 'NL', 'NB', 'NS', 'AB', 'BC', 'ON', 'SK', 'QC']\n",
    "entities = entities[~entities['state'].isin(canadian_provinces)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2015    4142\n",
       "2014    3332\n",
       "2013    2770\n",
       "2012    2333\n",
       "2011    2106\n",
       "2010    1942\n",
       "2009    1836\n",
       "2008    1726\n",
       "2007    1583\n",
       "2006    1577\n",
       "2005    1567\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many records per year (includes duplicates at a location)\n",
    "entities['year'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# remove all rows that contain 'airport' or 'concourse' in their name or address column\n",
    "entities = entities[~entities['name'].str.lower().str.contains('airport')]\n",
    "entities = entities[~entities['address'].str.lower().str.contains('concourse').fillna(False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# extract street address without unit/etc, as cleanly as possible\n",
    "regex_pattern = '#|,|\\(|ste|suite|unit|warehouse|building|bldg'\n",
    "entities['address1'] = entities['address'].str.lower().str.split(regex_pattern, return_type='frame')[0]\n",
    "\n",
    "# create a full_address field to identify locations by street address\n",
    "entities['full_address'] = entities['address1'].str.strip() + ' ' + entities['city'].str.strip() +  ' ' + entities['state'].str.strip()\n",
    "entities['full_address'] = entities['full_address'].str.replace('.',  '').str.lower().str.strip()\n",
    "\n",
    "# all done - drop the address1 column\n",
    "entities.drop('address1', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21001 n tatum blvd phoenix az            19\n",
       "3702 se hawthorne blvd portland or       17\n",
       "131 excelsior ave saratoga springs ny    17\n",
       "925 s 3rd st la crosse wi                16\n",
       "10426 e jomax rd scottsdale az           15\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# which addresses the appear most often in the data set?\n",
    "entities['full_address'].value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>id</th>\n",
       "      <th>last_update</th>\n",
       "      <th>name</th>\n",
       "      <th>state</th>\n",
       "      <th>type</th>\n",
       "      <th>updated</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>zip</th>\n",
       "      <th>full_address</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1187</th>\n",
       "      <td> 21001 N. Tatum Blvd.</td>\n",
       "      <td> Phoenix</td>\n",
       "      <td>  NaN</td>\n",
       "      <td> 1500</td>\n",
       "      <td>       NaT</td>\n",
       "      <td>                    BJ's Brewhouse</td>\n",
       "      <td> AZ</td>\n",
       "      <td> BrewHouse</td>\n",
       "      <td>2011-10-17</td>\n",
       "      <td>-111.9774</td>\n",
       "      <td> 33.6774</td>\n",
       "      <td> 85050</td>\n",
       "      <td> 21001 n tatum blvd phoenix az</td>\n",
       "      <td> 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1772</th>\n",
       "      <td> 21001 N. Tatum Blvd.</td>\n",
       "      <td> Phoenix</td>\n",
       "      <td>  NaN</td>\n",
       "      <td> 2273</td>\n",
       "      <td>       NaT</td>\n",
       "      <td> Rock Bottom Restaurant &amp; Brewery </td>\n",
       "      <td> AZ</td>\n",
       "      <td>   BrewPub</td>\n",
       "      <td>2011-11-01</td>\n",
       "      <td>-111.9774</td>\n",
       "      <td> 33.6774</td>\n",
       "      <td> 85050</td>\n",
       "      <td> 21001 n tatum blvd phoenix az</td>\n",
       "      <td> 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384 </th>\n",
       "      <td> 21001 N. Tatum Blvd.</td>\n",
       "      <td> Phoenix</td>\n",
       "      <td> U.S.</td>\n",
       "      <td> 1500</td>\n",
       "      <td>2011-10-15</td>\n",
       "      <td>                    BJ's Brewhouse</td>\n",
       "      <td> AZ</td>\n",
       "      <td> BrewHouse</td>\n",
       "      <td>       NaT</td>\n",
       "      <td>-111.9774</td>\n",
       "      <td> 33.6774</td>\n",
       "      <td> 85050</td>\n",
       "      <td> 21001 n tatum blvd phoenix az</td>\n",
       "      <td> 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2847</th>\n",
       "      <td> 21001 N. Tatum Blvd.</td>\n",
       "      <td> Phoenix</td>\n",
       "      <td> U.S.</td>\n",
       "      <td> 2273</td>\n",
       "      <td>2013-05-15</td>\n",
       "      <td> Rock Bottom Restaurant &amp; Brewery </td>\n",
       "      <td> AZ</td>\n",
       "      <td>   BrewPub</td>\n",
       "      <td>       NaT</td>\n",
       "      <td>-111.9774</td>\n",
       "      <td> 33.6774</td>\n",
       "      <td> 85050</td>\n",
       "      <td> 21001 n tatum blvd phoenix az</td>\n",
       "      <td> 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494 </th>\n",
       "      <td> 21001 N. Tatum Blvd.</td>\n",
       "      <td> Phoenix</td>\n",
       "      <td> U.S.</td>\n",
       "      <td> 1500</td>\n",
       "      <td>2014-10-14</td>\n",
       "      <td>       BJâ€™s Restaurant &amp; Brewhouse</td>\n",
       "      <td> AZ</td>\n",
       "      <td> BrewHouse</td>\n",
       "      <td>       NaT</td>\n",
       "      <td>-111.9774</td>\n",
       "      <td> 33.6774</td>\n",
       "      <td> 85050</td>\n",
       "      <td> 21001 n tatum blvd phoenix az</td>\n",
       "      <td> 2015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   address     city country    id last_update  \\\n",
       "1187  21001 N. Tatum Blvd.  Phoenix     NaN  1500         NaT   \n",
       "1772  21001 N. Tatum Blvd.  Phoenix     NaN  2273         NaT   \n",
       "384   21001 N. Tatum Blvd.  Phoenix    U.S.  1500  2011-10-15   \n",
       "2847  21001 N. Tatum Blvd.  Phoenix    U.S.  2273  2013-05-15   \n",
       "494   21001 N. Tatum Blvd.  Phoenix    U.S.  1500  2014-10-14   \n",
       "\n",
       "                                   name state       type    updated         x  \\\n",
       "1187                     BJ's Brewhouse    AZ  BrewHouse 2011-10-17 -111.9774   \n",
       "1772  Rock Bottom Restaurant & Brewery     AZ    BrewPub 2011-11-01 -111.9774   \n",
       "384                      BJ's Brewhouse    AZ  BrewHouse        NaT -111.9774   \n",
       "2847  Rock Bottom Restaurant & Brewery     AZ    BrewPub        NaT -111.9774   \n",
       "494         BJâ€™s Restaurant & Brewhouse    AZ  BrewHouse        NaT -111.9774   \n",
       "\n",
       "            y    zip                   full_address  year  \n",
       "1187  33.6774  85050  21001 n tatum blvd phoenix az  2013  \n",
       "1772  33.6774  85050  21001 n tatum blvd phoenix az  2013  \n",
       "384   33.6774  85050  21001 n tatum blvd phoenix az  2014  \n",
       "2847  33.6774  85050  21001 n tatum blvd phoenix az  2014  \n",
       "494   33.6774  85050  21001 n tatum blvd phoenix az  2015  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what entities are operating at the most common address?\n",
    "most_common_address = entities['full_address'].value_counts().index[0]\n",
    "entities[entities['full_address']==most_common_address].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a new dataframe to capture locations, based on address, agnostic to entity operating at it\n",
    "locations_columns = ['address', 'city', 'country', 'id', 'last_update', \n",
    "                     'name', 'state', 'type', 'updated', 'x', 'y', 'zip', \n",
    "                     'year', 'first_appearance', 'final_appearance', 'full_address']\n",
    "locations = pd.DataFrame(columns = locations_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process took 52.74 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time()\n",
    "for _, row in entities.iterrows():\n",
    "    \n",
    "    # check if this address already appears in the locations\n",
    "    matching_location = locations[locations['full_address'] == row['full_address']]\n",
    "    \n",
    "    # first check if this address appears multiple times - it shouldn't\n",
    "    if len(matching_location) > 1:\n",
    "        print 'problem: more than one row with this address'\n",
    "      \n",
    "    if len(matching_location) == 1:\n",
    "        # address is already in there so check if years need updating\n",
    "        loc_row = matching_location.index[0]\n",
    "        \n",
    "        # if the year is earlier in original data set then locations first year, update locations\n",
    "        if int(row['year']) < int(locations.loc[loc_row, 'first_appearance']):\n",
    "            locations.loc[loc_row, 'first_appearance'] = row['year']\n",
    "        \n",
    "        # if the year is later in original data set then locations final year, update locations\n",
    "        if int(row['year']) > int(locations.loc[loc_row, 'final_appearance']):\n",
    "            locations.loc[loc_row, 'final_appearance'] = row['year']\n",
    "            \n",
    "    else:\n",
    "        # this address isn't in locations data set yet, so add it with this year\n",
    "        loc_label = len(locations)\n",
    "        locations.loc[loc_label, entities_columns] = row[entities_columns]\n",
    "        locations.loc[loc_label, 'first_appearance'] = row['year']\n",
    "        locations.loc[loc_label, 'final_appearance'] = row['year']\n",
    "        \n",
    "print 'process took %s seconds' % round(time() - start_time, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sort data set by zip code\n",
    "locations_cleaned = locations.sort(columns='zip', ascending=False)\n",
    "locations_cleaned = locations_cleaned.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# function to handle geocoding logic\n",
    "def geocode(query):\n",
    "    \n",
    "    latlong = { }\n",
    "    url = 'https://maps.googleapis.com/maps/api/geocode/json?sensor=false&address={0}&key={1}'\n",
    "    apikey = '' #api key here\n",
    "    request = url.format(query, apikey)\n",
    "    data = json.loads(requests.get(request).text)\n",
    "    if len(data['results']) > 0:\n",
    "        latlong = {'lat':data['results'][0]['geometry']['location']['lat'] ,'lon':data['results'][0]['geometry']['location']['lng']}\n",
    "\n",
    "    return latlong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# reset the full_address field to a geocodable string\n",
    "locations_cleaned['full_address'] = locations_cleaned['address'].str.strip() + ', ' + locations_cleaned['city'].str.strip() +  ', ' + locations_cleaned['state'].str.strip() +  ', ' + locations_cleaned['zip'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 50 90 100 130 180 200 290 330 340 370 380 390 490 520 620 660 690 700 730 740 750 790 860 900 920 930 940 970 1030 1110 1130 1160 1210 1220 1240 1390 1410 1500 1550 1590 1620 1650 1660 1700 1710 1790 1800 1860 1900 1940 1980 1990 2030 2070 2080 2160 2180 2220 2270 2280 2380 2410 2490 2530 2580 2590 2610 2650 2660 2670 2730 2760 2770 2780 2790 2870 2950 3000 3080 3090 3110 3150 3160 3230 3260 3310 3370 3380 3390 3430 3440 3470 3540 3710 3720 3800 3810 3830 3990 4020 4030 4040 4080 4130 4140 4150 4160 4190 4280 4290 4310 4320 4380 4430 4470 4520 4530 4540 4560 4580 4630 4740 4760 4780 4820 4890 4920 5020 5030 5040 5050 5070 5090 5110 5130 5160 5170 5190 5210 5220 5260 5370 5390 5410 5440 5450 5490 5520 5580 5640 5650 5660 \n",
      "1576 rows geocoded.\n"
     ]
    }
   ],
   "source": [
    "# geocode address to lat-long for rows where lat-long is missing\n",
    "count = 0\n",
    "for label, row in locations_cleaned.iterrows():\n",
    "    if pd.isnull(row['x']) | pd.isnull(row['y']):\n",
    "        count = count + 1\n",
    "        if label % 10 == 0: print label,\n",
    "        latlong = geocode(row['full_address'])\n",
    "        if latlong != { }:\n",
    "            locations_cleaned.loc[label, 'y'] = latlong['lat']\n",
    "            locations_cleaned.loc[label, 'x'] = latlong['lon']\n",
    "print '\\n' + str(count) + ' rows geocoded.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# remove unnecessary columns\n",
    "locations_cleaned = locations_cleaned.drop(axis=1, labels=['country', 'last_update', 'updated', 'year', 'index', 'full_address'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many rows lack x or y?\n",
    "len(locations_cleaned[pd.isnull(locations_cleaned['x']) | pd.isnull(locations_cleaned['y'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# drop all rows that lack lat or long (after we geocoded addresses earlier)\n",
    "locations_cleaned['x'] = locations_cleaned['x'].astype(np.float)\n",
    "locations_cleaned['y'] = locations_cleaned['y'].astype(np.float)\n",
    "locations_cleaned = locations_cleaned[~(pd.isnull(locations_cleaned['x']) | pd.isnull(locations_cleaned['y']))]\n",
    "locations_cleaned = locations_cleaned[~((locations_cleaned['x'] == 0) | (locations_cleaned['y'] == 0))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CA    821\n",
       "CO    354\n",
       "OR    345\n",
       "WA    321\n",
       "MI    282\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# which states have the most locations in the data set?\n",
    "locations_cleaned['state'].value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>final_appearance</th>\n",
       "      <th>first_appearance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>  804</td>\n",
       "      <td> 1557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>  150</td>\n",
       "      <td>  797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>   80</td>\n",
       "      <td>  178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>  147</td>\n",
       "      <td>  219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>   76</td>\n",
       "      <td>  233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>  113</td>\n",
       "      <td>  175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>  106</td>\n",
       "      <td>  274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>   75</td>\n",
       "      <td>  334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>  120</td>\n",
       "      <td>  504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>  186</td>\n",
       "      <td>  656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td> 4046</td>\n",
       "      <td>  976</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      final_appearance  first_appearance\n",
       "2005               804              1557\n",
       "2006               150               797\n",
       "2007                80               178\n",
       "2008               147               219\n",
       "2009                76               233\n",
       "2010               113               175\n",
       "2011               106               274\n",
       "2012                75               334\n",
       "2013               120               504\n",
       "2014               186               656\n",
       "2015              4046               976"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many locations made their first or their final appearances in each year?\n",
    "pd.DataFrame({'first_appearance' : locations_cleaned['first_appearance'].value_counts(), \n",
    "              'final_appearance' : locations_cleaned['final_appearance'].value_counts()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>state</th>\n",
       "      <th>type</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>zip</th>\n",
       "      <th>first_appearance</th>\n",
       "      <th>final_appearance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2105</th>\n",
       "      <td>      1427 W Elizabeth St</td>\n",
       "      <td> Fort Collins</td>\n",
       "      <td>  NaN</td>\n",
       "      <td> C.B. &amp; Potts Restaurants-Big Horn Breweries </td>\n",
       "      <td> CO</td>\n",
       "      <td>      BrewPub</td>\n",
       "      <td>-105.102499</td>\n",
       "      <td> 40.573884</td>\n",
       "      <td> 80521</td>\n",
       "      <td> 2005</td>\n",
       "      <td> 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2106</th>\n",
       "      <td>        133 Remington St.</td>\n",
       "      <td> Fort Collins</td>\n",
       "      <td> 2606</td>\n",
       "      <td>                          Equinox Brewing Co.</td>\n",
       "      <td> CO</td>\n",
       "      <td> MicroBrewery</td>\n",
       "      <td>-105.075550</td>\n",
       "      <td> 40.586520</td>\n",
       "      <td> 80521</td>\n",
       "      <td> 2011</td>\n",
       "      <td> 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2107</th>\n",
       "      <td> 470 Prospect Village Dr.</td>\n",
       "      <td>   Estes Park</td>\n",
       "      <td>  NaN</td>\n",
       "      <td>                           Estes Park Brewery</td>\n",
       "      <td> CO</td>\n",
       "      <td>      BrewPub</td>\n",
       "      <td>-105.526121</td>\n",
       "      <td> 40.371419</td>\n",
       "      <td> 80517</td>\n",
       "      <td> 2005</td>\n",
       "      <td> 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2108</th>\n",
       "      <td>         285 Cheesman St.</td>\n",
       "      <td>         Erie</td>\n",
       "      <td> 4185</td>\n",
       "      <td>            Industrial Revolution Brewing Co.</td>\n",
       "      <td> CO</td>\n",
       "      <td> MicroBrewery</td>\n",
       "      <td>-105.048560</td>\n",
       "      <td> 40.051518</td>\n",
       "      <td> 80516</td>\n",
       "      <td> 2014</td>\n",
       "      <td> 2015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       address          city    id  \\\n",
       "2105       1427 W Elizabeth St  Fort Collins   NaN   \n",
       "2106         133 Remington St.  Fort Collins  2606   \n",
       "2107  470 Prospect Village Dr.    Estes Park   NaN   \n",
       "2108          285 Cheesman St.          Erie  4185   \n",
       "\n",
       "                                              name state          type  \\\n",
       "2105  C.B. & Potts Restaurants-Big Horn Breweries     CO       BrewPub   \n",
       "2106                           Equinox Brewing Co.    CO  MicroBrewery   \n",
       "2107                            Estes Park Brewery    CO       BrewPub   \n",
       "2108             Industrial Revolution Brewing Co.    CO  MicroBrewery   \n",
       "\n",
       "               x          y    zip first_appearance final_appearance  \n",
       "2105 -105.102499  40.573884  80521             2005             2010  \n",
       "2106 -105.075550  40.586520  80521             2011             2015  \n",
       "2107 -105.526121  40.371419  80517             2005             2015  \n",
       "2108 -105.048560  40.051518  80516             2014             2015  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show a slice of the data set\n",
    "locations_cleaned.iloc[2100:2104]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save the data set to csv\n",
    "locations_cleaned.to_csv('locations.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# add census fips code to each row - create new column to contain it\n",
    "locations_cleaned['block_fips'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 50 100 150 200 250 300 350 400 450 500 550 600 650 700 750 800 850 900 950 1000 1050 1100 1150 1200 1250 1300 1350 1400 1450 1500 1550 1600 1650 1700 1750 1800 1850 1900 1950 2000 2050 2100 2150 2200 2250 2300 2350 2400 2450 2500 2550 2600 2650 2700 2750 2800 2850 2900 2950 3000 3050 3100 3150 3200 3250 3300 3350 3400 3450 3500 3550 3600 3650 3700 3750 3800 3850 3900 3950 4000 4050 4100 4150 4200 4250 4300 4350 4400 4450 4500 4550 4600 4650 4700 4750 4800 4850 4900 4950 5000 5050 5100 5150 5200 5250 5300 5350 5400 5450 5500 5550 5600 5650 5700 5750 5800 5850 5900\n"
     ]
    }
   ],
   "source": [
    "# for each row in the dataframe\n",
    "for label, row in locations_cleaned.iterrows():\n",
    "    \n",
    "    # if this row does not already have fips data\n",
    "    if pd.isnull(row['block_fips']):\n",
    "        \n",
    "        # create a parameterized url and insert the latitude and longitude values as the parameters\n",
    "        url = 'http://data.fcc.gov/api/block/find?format=json&latitude={0}&longitude={1}&showall=true'\n",
    "        url = url.format(str(row['y']), str(row['x']))\n",
    "\n",
    "        # fetch and load the JSON response from the API\n",
    "        response = requests.get(url)\n",
    "        data = json.loads(response.text)\n",
    "\n",
    "        # save the data to this row in the dataframe\n",
    "        locations_cleaned.loc[label, 'block_fips'] = data['Block']['FIPS']\n",
    "    \n",
    "    if label % 50 == 0: print label,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>state</th>\n",
       "      <th>type</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>zip</th>\n",
       "      <th>first_appearance</th>\n",
       "      <th>final_appearance</th>\n",
       "      <th>block_fips</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5913</th>\n",
       "      <td>            3020 Water St.</td>\n",
       "      <td>   Bay City</td>\n",
       "      <td> 1581</td>\n",
       "      <td>              Tri-City Brewing Co.</td>\n",
       "      <td> MI</td>\n",
       "      <td> MicroBrewery</td>\n",
       "      <td> -83.865100</td>\n",
       "      <td> 43.608800</td>\n",
       "      <td> NaN</td>\n",
       "      <td> 2007</td>\n",
       "      <td> 2011</td>\n",
       "      <td> 260172865001026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5914</th>\n",
       "      <td> 2500 S. Harbor City Blvd.</td>\n",
       "      <td>  Melbourne</td>\n",
       "      <td>  NaN</td>\n",
       "      <td>          Indian River Brewing Co.</td>\n",
       "      <td> FL</td>\n",
       "      <td> MicroBrewery</td>\n",
       "      <td> 100.773042</td>\n",
       "      <td> 18.775632</td>\n",
       "      <td> NaN</td>\n",
       "      <td> 2008</td>\n",
       "      <td> 2014</td>\n",
       "      <td>            None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5915</th>\n",
       "      <td>                       NaN</td>\n",
       "      <td>   Big Bend</td>\n",
       "      <td>  NaN</td>\n",
       "      <td>    Longnecks Brewpub &amp; Restaurant</td>\n",
       "      <td> WI</td>\n",
       "      <td>          NaN</td>\n",
       "      <td> 100.773042</td>\n",
       "      <td> 18.775632</td>\n",
       "      <td> NaN</td>\n",
       "      <td> 2008</td>\n",
       "      <td> 2008</td>\n",
       "      <td>            None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5916</th>\n",
       "      <td>                       NaN</td>\n",
       "      <td>   San Jose</td>\n",
       "      <td> 2879</td>\n",
       "      <td> Shizmo Brewing Co. (by appt only)</td>\n",
       "      <td> CA</td>\n",
       "      <td> MicroBrewery</td>\n",
       "      <td>-121.894955</td>\n",
       "      <td> 37.339386</td>\n",
       "      <td> NaN</td>\n",
       "      <td> 2011</td>\n",
       "      <td> 2011</td>\n",
       "      <td> 060855008001000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5917</th>\n",
       "      <td>                       NaN</td>\n",
       "      <td> Santa Cruz</td>\n",
       "      <td> 3516</td>\n",
       "      <td>                Lucky Hand Brewing</td>\n",
       "      <td> CA</td>\n",
       "      <td> MicroBrewery</td>\n",
       "      <td> 100.773042</td>\n",
       "      <td> 18.775632</td>\n",
       "      <td> NaN</td>\n",
       "      <td> 2013</td>\n",
       "      <td> 2013</td>\n",
       "      <td>            None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        address        city    id  \\\n",
       "5913             3020 Water St.    Bay City  1581   \n",
       "5914  2500 S. Harbor City Blvd.   Melbourne   NaN   \n",
       "5915                        NaN    Big Bend   NaN   \n",
       "5916                        NaN    San Jose  2879   \n",
       "5917                        NaN  Santa Cruz  3516   \n",
       "\n",
       "                                   name state          type           x  \\\n",
       "5913               Tri-City Brewing Co.    MI  MicroBrewery  -83.865100   \n",
       "5914           Indian River Brewing Co.    FL  MicroBrewery  100.773042   \n",
       "5915     Longnecks Brewpub & Restaurant    WI           NaN  100.773042   \n",
       "5916  Shizmo Brewing Co. (by appt only)    CA  MicroBrewery -121.894955   \n",
       "5917                 Lucky Hand Brewing    CA  MicroBrewery  100.773042   \n",
       "\n",
       "              y  zip first_appearance final_appearance       block_fips  \n",
       "5913  43.608800  NaN             2007             2011  260172865001026  \n",
       "5914  18.775632  NaN             2008             2014             None  \n",
       "5915  18.775632  NaN             2008             2008             None  \n",
       "5916  37.339386  NaN             2011             2011  060855008001000  \n",
       "5917  18.775632  NaN             2013             2013             None  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the tail of the data set\n",
    "locations_cleaned.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(locations_cleaned[pd.isnull(locations_cleaned['block_fips'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fips 021300001004012\n",
      "state 02\n",
      "county 130\n",
      "tract 000100\n",
      "block 4012\n"
     ]
    }
   ],
   "source": [
    "# fips code is 2 digit state, 3 digit county, 6 digit tract, 4 digit block (the first digit of which is the block group)\n",
    "fips = locations_cleaned.loc[0, 'block_fips']\n",
    "print 'fips', fips\n",
    "print 'state', fips[0:2]\n",
    "print 'county', fips[2:5]\n",
    "print 'tract', fips[5:11]\n",
    "print 'block', fips[11:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# add the tract fips as a new column to the data set\n",
    "locations_cleaned['tract_fips'] = locations_cleaned['block_fips'].str.slice(start=0, stop=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save the data set to csv\n",
    "locations_cleaned.to_csv('locations-fips.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_types = {'zip':str, 'block_fips':str, 'tract_fips':str}\n",
    "locations_cleaned = pd.read_csv('locations-fips.csv', encoding='utf-8', converters=data_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a new dataframe to de-dupe locations, based on name + block_fips\n",
    "locations_final_columns = ['address', 'city', 'id', 'name', 'state', 'type', 'x', 'y', 'zip', \n",
    "                           'first_appearance', 'final_appearance', 'block_fips', 'tract_fips', 'block_name']\n",
    "locations_final = pd.DataFrame(columns = locations_final_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5903"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locations_cleaned['block_name'] = locations_cleaned['block_fips'] + '+++' + locations_cleaned['name']\n",
    "len(locations_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process took 13.92 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5458"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = time()\n",
    "for _, row in locations_cleaned.iterrows():\n",
    "    \n",
    "    # check if this block_name already appears in the locations_final\n",
    "    matching_location = locations_final[locations_final['block_name'] == row['block_name']]\n",
    "    \n",
    "    # first check if this block_name appears multiple times - it shouldn't\n",
    "    if len(matching_location) > 1:\n",
    "        print 'problem: more than one row with this block_name'\n",
    "      \n",
    "    if len(matching_location) == 1:\n",
    "        # address is already in there so check if years need updating\n",
    "        match_label = matching_location.index[0]\n",
    "        \n",
    "        # if the year is earlier in original data set then locations first year, update locations\n",
    "        if int(row['first_appearance']) < int(locations_final.loc[match_label, 'first_appearance']):\n",
    "            locations_final.loc[match_label, 'first_appearance'] = row['first_appearance']\n",
    "        \n",
    "        # if the year is later in original data set then locations final year, update locations\n",
    "        if int(row['final_appearance']) > int(locations_final.loc[match_label, 'final_appearance']):\n",
    "            locations_final.loc[match_label, 'final_appearance'] = row['final_appearance']\n",
    "            \n",
    "    else:\n",
    "        # this address isn't in locations data set yet, so add it with this year\n",
    "        loc_label = len(locations_final)\n",
    "        locations_final.loc[loc_label, locations_final_columns] = row[locations_final_columns]\n",
    "        locations_final.loc[loc_label, 'first_appearance'] = row['first_appearance']\n",
    "        locations_final.loc[loc_label, 'final_appearance'] = row['final_appearance']\n",
    "        \n",
    "print 'process took %s seconds' % round(time() - start_time, 2)\n",
    "len(locations_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save the data set to csv\n",
    "locations_final = locations_final.drop(axis=1, inplace=False, labels=['block_name'])\n",
    "locations_final = locations_final.sort('block_fips')\n",
    "locations_final.to_csv('locations-final.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save a list of block_fips that appear more than once in the data set, to csv\n",
    "dupe_block_fips = locations_final[locations_final.duplicated(subset=['block_fips'])]['block_fips']\n",
    "dupe_block_fips.to_csv('dupe-block_fips.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
